# 《MySQL技术内幕：InnoDB存储引擎》

## 第六章 锁

### 前言

开发多用户，数据库驱动的应用时，最大的一个难点是：一方面要最大程度的利用数据库的并发访问，另一方面还要确保每个用户能以一致的方式读取和修改数据，为此就有了锁机制。同时这也是数据库系统区别于文件系统的一个关键特性。锁机制用于管理对共享资源的并发访问，InnoDB存储引擎会在行级别上对表数据上锁。

对于myisam引擎，其锁是表锁设计，并发情况下的读没有问题，但是并发插入时的性能就要差一些了。

InnoDB存储引擎的实现和orcal数据库非常类似，提供一致性的非锁定读，行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。

### lock和latch

latch：模式为：读写锁，互斥量。一般被称为轻量级的锁，因为其要求锁定的时间非常短，若持续的时间长了，应用的性能会变得很差。在InnoDB存储引擎中，latch又分为mutex(互斥量)与rwlock(读写锁)，其目的是用来保证并发线程操作临界资源的正确性，并且通常没有死锁的检测机制。

lock：模式为：行锁，表锁，意向锁。lock的对象是事务，用来锁定的是数据库中的对象，如表，页，行等。并且一般lock的对象仅在事务commit或rollback后进行释放，(不同事务的隔离级别释放的时间可能不同)，lock锁通过waits-for-graph，time-out机制来进行死锁检测和处理。

### InnoDB存储引擎中的锁

### 补充（关于锁的范围）

~~~wiki
全局锁：
根据加锁的范围，mysql里面的锁大致可以分为全局锁，表级锁以及行锁，全局锁就是对整个数据库加锁，mysql提供了一种读全局锁的方法，FTWRL，flush table whit read lock，当需要让整个库处于只读状态时，可以通过ftwrl，之后更新操作，删除操作，DDL语句以及更新类的事务提交语句都会被阻塞

全局锁的使用场景是做数据库的全局逻辑备份，也就是把整个库每个表都使用select出来存成文本。

官方自带的逻辑备份工具是mysql-dump，当使用mysql-dump-single-transaction时，备份过程会开启一个事务，来确保拿到一个一致性视图，而由于MVCC的支持，读操作在这个视图上进行，其他写操作不阻塞。
对于myisam这种不支持事务的存储引擎，如果要在全局备份的时候做更新操作，就只能使用ftwrl这种锁全局的方式

表级锁：
mysql里面表级别的锁有两种，一种是表锁，一种是MDL，元数据锁
表级锁的语法是lock tables read/write，表级锁不仅会限制其他线程的读写操作，也会限制当前线程接下来操作的对象
另一个表级锁是MDL元数据锁，mysql5.5后引入MDL读锁和MDL写锁
当对一个表做增删改查操作的时候，加MDL读锁，当要对表结构做变更操作的时候，加MDL写锁
读锁之前不互斥，因此可以有多个线程对一张表增删改查，MDL的读写锁之间是互斥的，当一个线程在读写表记录，另一个线程删了表的一列，这个行为是阻塞的，比如等待一个完成以后才可以继续执行
由MDL元数据锁引发出来一个问题：如何给线上的表加字段
首先解决长事务问题，可以在information架构库中的事务表中查看当前表正在运行的事务，如果有长事务在执行，应该先不要DDL操作，否则一旦DDL操作被这个长事务阻塞，那么后面再来的线程即使只是想加个MDL读锁，也会被阻塞，越积累越多，并且客户端还有超时重试机制，再次发起一个新的session，很快连接池就会爆满，造成整张表完全不能读写
mysql再后来支持了在线DDL，在线DDL的过程是这样的：
1.先拿到MDL写锁
2.降级成MDL读锁
3.真正做DDL
4.升级成MDL写锁
5.释放MDL锁
只有第三步会耗费较多的时间，其他部分如果没有锁冲突，执行时间非常短，在第三步真正DDL的时间内，数据库是可以正常读写的，因此称为online DDL

行级锁：
在innodb存储引擎中，行锁是在需要的时候才加上去的，但并不是不需要了就释放掉，而是等到事务提交后才会释放，我就是二阶段锁协议
所以如果事务需要锁多个行，要把有可能造成锁冲突，最有可能影响并发的锁尽量放后面，将最可能并发操作的语句放在一个大事务的最后面，让他最晚上锁，锁定的时间短一些，可以最大程度减少锁之间的等待时间，提升了并发度
~~~

锁的类型：InnoDB存储引擎实现了如下两种标准的行级锁：

* 共享锁（S Lock），允许事务读一行数据
* 排他锁（X Lock），允许事务删除或更新一行数据

读锁仅与读锁兼容，写锁与任何锁都不兼容。

此外，InnoDB存储引擎支持多粒度锁定，这种锁定允许事务在行级上的锁与表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称为意向锁，意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度上进行加锁。

### 一致性非锁定读

一致性的非锁定读是InnoDB存储引擎通过多版本并发控制的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行delete或update操作，这时读取操作不会因此去等待行上锁的释放，相反地，InnoDB存储引擎会去读取行的一个快照数据

之所以称为非锁定读，因为不需要等待访问的行上排他锁的释放，快照数据是指改行的之前的版本，该实现是通过undo段来完成，而undo用来在事务中回滚数据，因此快照数据本身是没有额外开销的。此外，读取快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作（历史不可篡改）。

一致性非锁定读极大地提高了数据库的并发性。在InnoDB存储引擎的默认设置下，这是默认的读取方式。即读取不会占用和等待表上的锁。

但是在不同的事务隔离级别下，读取的方式是不同的。

快照数据其实就是当前行数据之前的历史版本，每行记录可能有多个版本。一个行记录可能有不止一个快照数据，一般称这种技术为多版本并发控制。

在读已提交和可重复读隔离级别下，InnoDB存储引擎使用非锁定的一致性读。然而他们对于快照数据的定义是不同的。在读已提交下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据。而在可重复读下，对于快照数据，一致性非锁定读总是读取事务开始时的行数据版本。

### 一致性锁定度

在默认配置下，InnoDB存储引擎的事务隔离级别为可重复读，这个时候InnoDB存储引擎的select操作使用一致性非锁定读，但是在某些情况下，用户需要显示地对数据库读取操作进行加锁以保证数据库逻辑的一致性。而这要求数据库支持加锁语句，即使是对于select的只读操作，InnoDB存储引擎对于select语句支持两种一致性锁定读操作：

* select....for update
* select ...lock in share mode

select....for update对读取的行记录加一个X锁，其他事务不能对已锁定的行记录加上任何锁。

select ...lock in share mode对读取的行记录加上一个S锁，其他事务可以向被锁定的行记录再加S锁，但是不能加X锁，会被阻塞。

对于一致性非锁定读，即使读取的行记录上加了显示的锁，比如select....for update，也是可以进行读取的，只不过读取的是行上的一个快照数据。此外select....for update，select ...lock in share mode必须在一个事务中，当事务提交了，锁也就释放了。因此在使用上述两个语句时，必须加上begin，start transaction或者set autocommit = 0

### 自增长与锁

自增长在数据库中是一种非常常见的属性，也是很多开发人员首选的一种主键方式，在InnoDB存储引擎内部，对于每一个含有自增长值的表都有一个自增长计数器，插入操作通过这个自增长的计数器值加一来赋予自增长列。这个实现方式叫auto-inc-locking。这种锁采用的是一种优化后的表锁机制，为了提高插入的性能，锁不是在一个事务完成后才释放的，而是在完成对自增长值插入的sql语句后立即释放。

这种机制从一定程度上提高了并发性，但是在并发插入上性能依然较差，事务必须等待前一个事务中的sql语句执行完了才可以插入。

特别注意：

InnoDB存储引擎中的自增长的实现与myisam不同，myisam引擎采用的是表锁设计，自增长不需要考虑并发插入的问题。

对于主从架构采用不同存储引擎的方案，需要特别注意。

同时注意：

对于InnoDB存储引擎，自增长的列必须是索引，同时必须是索引的第一个列。myisam没有这个要求。

### 外键和锁

外键主要用于引用完整性的约束检查，在InnoDB存储引擎中，对于一个外键列，如果没有显示地为外键列加索引，InnoDB存储引擎会自动地为外键列加一个索引，因为这样可以避免表锁。（死锁？？）

对于外键值的插入或更新，首先需要查询父表的记录，即select 父表，但是对于父表的select操作，因为这时使用的是select lock in share mode方式。即主动对父表加了一个S锁，如果这时父表已经加了X锁，子表上的操作会被阻塞的。

设想一下如果访问父表时使用的是一致性非锁定读，那么会读到快照数据，如果满足插入条件，那么就直接插入了啊！但是如果另一个会话把这个记录删掉了，并且提交了，则父表中就并不存在这个数据了，造成了数据在子表，父表不一致的情况。

总之，生产级应用禁止使用外键，一切约束在应用层来实现。

### 锁的算法

### 行锁的三种算法

* record lock：单个行记录上的锁
* gap lock：锁定一个范围，但是不包括记录本身
* next key lock：锁定一个范围，包括行本身

record lock总会去锁住索引记录，如果InnoDB存储引擎在创建表的时候没有设置任何一个索引，InnoDB存储引擎会使用隐式创建的索引来锁定。

next key lock算法是结合了gap lock和record lock，InnoDB存储引擎对于行的查询都是使用这种锁定算法。

next key lock锁定算法的设计目的是为了解决幻读问题。

注意：

当查询的索引含有唯一属性的时候，也就是定义的时候指定了唯一约束，InnoDB存储引擎会对next key lock降级为record lock。

记住，锁降级的前提仅是被查询的列是唯一索引，才会降级为record lock。

InnoDB存储引擎会对辅助索引的下一个键值加上gap lock。

gap lock的设计目的是为了避免幻读。它的作用是防止不同事务将记录插入到同一个范围之内，这会导致幻读的产生。

用户可以通过设置隔离级别为RC来显示地关闭gap lock或者通过参数来设置。

最后再次注意：

对于唯一键值的锁定，next key lock降级为record lock仅存在于查询所有的唯一索引列，若唯一索引列由多个列构成，而查询只是查找其中的一个，那么查询其实是range类型查询，而不是point类型查询，不会降级。

### 解决幻读

默认RR隔离级别下，InnoDB存储引擎采用next key lock算法来避免幻读的产生。这点不同于其他数据库，在orcal中只有设置了SE隔离级别才会避免幻读的产生。

幻读是指，在同一事务中，连续执行两次相同的sql语句可能读到不同的结果，第二次执行的sql语句可能会返回之前不存在的行。

~~~sql
例子：
表中有记录 1,2,4
事务A执行以下操作：
select * from t where a > 2 for update 
应该能查到记录4
这时事务A没有提交

事务B执行以下操作：
begin;
insert into t select 5;
commit;

这时事务A继续执行那条sql语句，就会发生幻读现象。读取到了记录5
这种情况在InnoDB存储引擎的RR隔离级别下不会发生，因为使用了next key lock算法，锁住了2到正无穷的范围
~~~

### 锁问题

通过锁定机制可以实现事务的隔离性要求，使得事务可以并发地工作，锁提高了并发，但是会带来潜在的问题，不过好在由于事务隔离性的要求，锁只会带来三种问题，如果处理好以下三种问题，就不会发生异常。

### 脏读

理解脏读之前，先理解脏数据，脏数据和之前学习的脏页是完全不同的。脏页是指缓冲池中已经被修改的页，但是还没有刷新落盘，即数据库实例中内存与磁盘中的数据是不一致的，但是在刷新落盘之前，日志都已经被记录到了重做日志中。而脏数据指的是事务对数据进行了修改，但是还没有提交。

对于脏页的读取，是非常正常的，脏页是由于内存和磁盘的异步造成的，这个思想是最终一致性，数据最终会达到一致。并且脏页的刷新还是异步的，不影响数据的可用性，所以能带来性能的提高。

脏数据截然不同，脏数据是其他事务未提交的数据，如果读到了脏数据，这显然违反了事务的隔离性要求，即一个事务读取到了另一个事务未提交的数据。

RU，脏读隔离级别，最低的隔离级别，看似毫无用处，其实不然，在主从复制架构下，从节点的数据库上的查询不需要特别精准的值的时候可以使用RU隔离级别。

### 不可重复读

不可重复读指的是事务中两次查询的结果不一致，原因是其他事务做了更新的操作。

在第一个事务中的两次读数据之间，其他事务对数据做了更新。

注意脏读与不可重复读之间的区别主要是脏读是读到了未提交的事务，而不可重复读是读到了其他事务已经提交的数据。但是违反了数据库事务的一致性要求。一般来说，不可重复读的问题是可以接收的，毕竟是其他事务已经提交的数据。本身不会带来很大的问题。

在RR级别下，通过next key lock（record lock 锁住本身，避免修改这一条记录，造成不可重复读）算法，不仅锁住了索引，还锁住了索引覆盖的范围（gap lock 锁住范围，避免添加记录后的范围查询多了几条前面没有的记录，造成幻读），因此在这个范围内对于数据的插入都是不允许的。避免了不可重复读，也避免了幻读。

### 丢失更新问题

在这种问题中，一定要注意修改之前先查看记录，并对记录加排它锁。这样其他事务对数据更新一样不会覆盖你的更新。将这种转钱操作变为完全串行化，update之前先select for update加排它锁，防止丢失更新问题。

### 阻塞

因为不同锁的兼容性的原因，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源。这就是阻塞，这种机制不可避免，是为了确保事务可以并发且正常运行。

特别注意：

在默认情况下InnoDB存储引擎不会回滚超时引发的异常。比如以下场景：

~~~sql
有一个会话A ，开起了一个事务
begin；
查询一个范围，并加了一个一致性锁定读，且是排它锁，
select * from t  where a < 4 for update;
这相当于锁住了负无穷到4（包括记录4本身）的所有记录

又有一个会话B，开启了一个事务
begin；
insert into t select 5；
这显然不用阻塞
insert into t select 3；
阻塞，如果A事务一直不提交，那么阻塞到50秒后会超时，最终报1205阻塞lock wait timeout异常
try restart transaction
那么相当于你这个事务发生了异常了
我再次开启一个事务，并查询记录
发现5这个记录居然被插入成功了。
~~~

这种状态是十分危险的，用户必须判断是否需要commit还是rollback

### 死锁

~~~wiki
当并发系统中的不同线程之间出现循环资源依赖，涉及的线程都在等待别的线程释放资源，就会导致这几个线程进入循环依赖的状态，这就是死锁
~~~

死锁是指两个或两个以上的事务（或者理解为会话）在执行的过程中，因争夺锁资源而造成互相等待的一种情况。这个时候，若无外力介入，那么事务将无法进行下去。

解决死锁最容易想到的一种办法显然就是超时了，通过设置一个超时阈值，当等待时间超过这个阈值的时候，我们就让其中的一个事务回滚，具体哪个事务呢，如果我们时候不加思考，那么直接FIFO的顺序选择回滚对象，但是这样显然也是欠缺考虑的，因为可能有些较大的事务，比如事务操作更新很多行，那么这个事务已经占用了很多的undo log，如果回滚这个事务，可能要比另一个事务的所要花费的时间要长，不值得。

所有有了wait-for-graph(等待图)机制来检测死锁，较之超时机制，这是一种更加主动的死锁检测方式，InnoDB存储引擎就是采用了等待图的机制来进行死锁检测的。

wait-for-graph要求数据库保存以下两种信息：

* 锁的信息链表
* 事务等待链表

通过这些链表构建出一张图，如果这个图中存在回路，那么就代表存在死锁，因为资源间相互发生等待。在wait-for-graph中，事务为图中的节点，在图中，事务T1指向T2的边的定位为：

* 事务T1等待事务T2所占用的资源
* 事务T1最终等待事务T2所占用的资源，也就是事务之间在等待相同的资源，而事务T1发生在事务T2的后面

如果这个构建出来的图存在回路，那么说明这两条回路边的两个节点，节点对应的就是事务，存在死锁，那么存在死锁了，如何解决呢?上面提到了FIFO选取容易选到大事务，所以在等待图机制中，InnoDB存储引擎会回滚undo量最小的事务。

wait-for-graph的死锁检测通常采用深度优先的算法实现。在老版本采用的是递归，后面使用非递归的方式实现了，提高了InnoDB存储引擎的性能。

死锁演示

~~~sql
会话A：
begin；
select * from t where a = 1 for update;
.
.
事务没有提交

会话B:
begin;
select * from t where a = 2 for update;
.
.
事务没有提交

会话A：
select * from t where a = 2 for update;
阻塞等待。。

会话B:
select * from t where a = 1 for update;
deadlock found when trying get lock 1213错误

~~~

大多数的死锁InnoDB存储引擎会检测到的，不需要人为进行干预的。

同时，有没有回忆起刚才总结的？InnoDB存储引擎不会回滚大部分错误异常，但是死锁除外，死锁发生会立即回滚undo log较少的事务

### 锁升级

锁升级就是将当前的锁的粒度降低。比如说数据库会把一张表的1000条行锁升级为一个页锁，或者将页锁升级为表锁。数据库的设计者认为锁是一种稀缺资源，想要避免锁的开销，那数据库中会频繁出现锁升级的现象。

InnoDB存储引擎不存在锁升级的现象，因为其不是根据每个记录来产生锁的，他是根据每个事务访问的每个页对锁进行一个管理，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销都是一致的。不存在锁升级！！！

### 总结

本章需要学习到：理解锁带来的问题，锁本身是一种相当直接的概念，没什么可谈的，但是如果不理解它的问题：丢失更新，脏读，不可重复读等问题时，那么开发的应用程序性能就会很差，如果不学会一些命令和数据字典来查看当前事务锁住了哪些资源，那么你可能永远不知道底层到底发生了什么事情。