### 由delete drop引出重建表相关

innodb_file_per_table设置为ON，是推荐做法，表示将每个innodb表数据存储在一个以.ibd结尾的文件中

而且当不需要这个表的时候，通过drop table命令，可以直接删除这个文件，而如果是放在共享表空间中，即使表删除了，空间也是不会回收的

在删除整个表的时候，可以使用drop table命令回收表空间，但是实际遇到的更多的场景是删除其中的记录，这就衍生出一个问题，为什么表中的数据删除了，但是表空间没有被回收

如果使用delete命令删除表中所有的数据，结果是所有的数据页都被标记为可复用，但是磁盘上，文件不会变小，也就是说通过delete不能回收表空间，只是把数据页标记为了可复用，这就感觉像是表中有了一些空洞一样

不只是删除数据会造成空洞，插入数据也会

如果数据是按索引递增顺序插入，那么索引是紧凑的，但是如果是随机插入，那么可能造成索引的页分裂

也就是说经过大量增删改的表，都是可能存在空洞的，如果能把这些空洞去掉，就能达到收缩表空间的目的

重建表就能达到这个目的

重建表的思路是建立一张与表A结构相同的表B，然后将表A的数据按主键索引递增的顺序插入到表B，很显然，表B的主键索引更紧凑，数据页的利用率也更高，如果把表B作为临时表，插入完成以后，用表B替换表A ，就完成了表的重建工作。

但是上面这种做法一个问题，如果在从表A往临时表B中插入数据的时候，表A又有了新的数据，那么重建完成以后还造成更新丢失的情况，所以在插入临时表期间，不可以更新。这是mysql5.6以前的版本，没有online DDL功能

可以通过alter table A engine = innodb

在mysql5.6以后，引入了online DDL，步骤是：

1.建立一个临时文件，扫描表A主键的所在数据页

2.用数据页中表A的记录生成一个B+树，放到临时文件中

3.生成临时文件时，也就是往临时表添加数据的过程中，会把表A的更新操作记录起来，记录到一个叫rowlog 的文件中

4.临时文件生成以后，将日志文件中的操作应用的临时文件，得到一个逻辑上与表A一致的临时表B

5.将表B替换表A，完成重建工作

在线DDL需要在DDL之前拿到MDL写锁，虽然MDL写锁最终会降级成MDL读锁，是可以在DDL期间进行更新操作的，不阻塞更新操作，至于说不直接解锁的原因是为了保护自己，防止其它线程也对这个表做DDL操作，MDL是一个表级锁

对于一个大表来说，重建表最耗时的操作是拷贝数据到临时表的时间，但是这个过程可以接收增删改操作，所以对于整个DDL过程来说，锁的时间只是刚开始获取MDL写锁，然后降级为MDL读锁，做DDL的过程中相当于一直是表级锁MDL的读锁状态，不阻塞，所以业务上看起来就是online DDL，但是即使不阻塞，对于很大的表，这个操作还是很消耗IO和CPU的

inplace概念：

根据表A重建出来的数据是放在temp_file中的，这个临时文件时innodb在内部创建出来的，整个DDL过程都是在innodb内部完成的，对于server层来说，没有把数据挪到临时表，是一个原地操作，这就是inplace名称的来源

mysql5.6开始，alter table t engine = innodb默认就是recreate过程

analyze table ：对表的索引信息做重新统计，没有修改数据，这个过程会加MDL读锁

optimize table等于recreate + analyze

### 关于count(*)

对于不同的存储引擎，count(*)的实现是不同的。

myisam会把一个表的总行数存放在磁盘上，因此执行count(*)的时候直接返回这个数，效率很高

innodb比较麻烦，在执行count(*)的时候，需要把数据一行一行从引擎中取出来，然后累积计数

innodb没有把这个总行数像myisam一样把行数存起来是因为即使是在同一时刻的多个查询，由于多版本并发控制，innodb对于应该返回多少行也是不确定的。

思考这样一个场景：同一时刻有三个会话：

![image](https://cdn.jsdelivr.net/gh/chen-xing/figure_bed_02/cdn/20210903140209854.png)

由于多版本并发控制，不同会话只能读取到当前会话事务开启那一刻的数据快照，并且在同一个事务内，多次读取都是以那个快照版本为准，如果是RR的话，这是可重复读实现的根本依据

那么可以看到对于第一个会话，它开启的时候数据总共有10000行，所以不管这个事务运行了多长时间，最终返回都是10000，会话B比会话A开启的晚，晚到会话C已经插入了一行才开启，这时候读到了这个快照版本，所以在他的事务内，它自己也插入了一条记录，最终读到的就是10002，对于会话C，它在自己的事务内插入一条记录，最终读取的也是自己快照版本+1，最终三个会话在同一时刻在各自的事务内读出来了三个不同的结果

这种情况是跟innodb实现事务有关，RR是默认隔离级别，在代码上通过mvcc多版本并发控制来实现，每一行记录都判断自己是否对这个会话可见，因此count(*)只好把数据一行一行读取出来，可见的行才能用于统计计算

所以由于事务的原因，innodb是无法像myisam一样直接存统计结果，mysql对count(*)是有一定优化的：innodb是索引组织表，主键索引树的叶子节点是整行数据，普通索引树的叶子节点是主键值，所以普通索引树的大小是远小于主键索引树的，但是对这两棵树做数字统计运算的逻辑结果是一致的，因此，mysql会找较小的那颗树进行遍历

count(*)和count（主键id）count（1）都是表示返回满足条件的结果集的总行数，而count（字段），表示返回满足条件的数据行里面，参数字段不为null的总个数

对于count（主键id）来说，innodb会遍历整张表，每一行的id值都取出来，返回给server层，server层拿到id后，判断是不可能为空的，就按行累加，其实对于count(主键id)这个是可以优化成与count(*)一样逻辑的，但是并没有，所以建议直接count(※)

对于count（1）来说，innodb会遍历整张表，但不取值，server层对于返回的每一行，放一个数字1进去，判断是不可能为空的，按行累加

count（1）是比count（主键id）要快，因为引擎层需要返回id涉及到解析数据行，以及拷贝字段值的操作

对于count（字段）来说：由于要判断行记录中的字段，所以肯定需要走主键索引拿到行记录，在行记录中拿到字段，进行null判断

1.如果这个字段是定义为not null，那么就取出所有行中的这个字段，判断不能为null，按行累加

2.如果字段定义允许为null，那么执行的时候判断是否为null，不是null才累加

count(*)做了优化，也就是在索引树较小的树上遍历，并不会直接在主键索引树上遍历，并且取出结果以后不取值，而且肯定不是null，直接累加，按照效率：count（字段）< count（主键id）< count（1）<  count（※）

### 关于二阶段提交不在不同时刻出现异常的情况

1.当在写入redo然后处于redo的prepare状态的时候，在写binlog，这个期间发生了宕机，由于此时binlog还没写，redo也没commit，所以在崩溃恢复的时候事务会回滚，这个时候binlog没写，错误信息不会转移到从库

2.如果在redo prepare后，并且binlog也开始写了，在写binlog到redo的commit标识这段时间内，如果宕机，这个时候崩溃恢复需要有一个判断规则：

如果redo里面的事务是完整的，也就是里面已经有了commit标识，则宕机后直接恢复

如果redo里面的事务只有完成的prepare，则判断对应的事务的binlog是否完整，如果binlog是完整的，则提交事务，否则回滚事务

所以如果在redo的一阶提交完成以后，也就是prepare后，并且binlog已经写完了，这时候的崩溃恢复是会提交事务的

### 如何判断崩溃恢复时binlog是否完整？

一个完整的binlog是有完整格式的：

对于statement格式的binlog，最后会有commit

对于row格式的binlog，最后会有一个XIDevent

对于5.6以后，还引入了binlog-checksum参数，用来验证binlog内容的正确性，对于binlog日志由于磁盘原因，可能会在日志中间出错的情况，mysql可以通过checksum的结果来发现

### redolog和binlog的联系

他们有一个共同的字段是xid，崩溃恢复的时候会按顺序扫描redo

如果在redo中找到了prepare标识和commit，那么可以证明binlog已经写入完整，直接提交

如果redo中只有prepare，没有commit，就拿着xid去binlog找对应的事务

### 处于prepare阶段的redo加上完整的binlog，重启就能恢复

因为一旦有了完整的binlog，那么从库就可以拿去使用做主从复制了，所以主库一定要提交事务，从而保证主库和从库之间的数据一致性

### 那么接上一个问题，为什么还需要二阶提交，直接干脆先把redo完整写完，再写binlog，必须两个日志完整，才可以提交，不是一样的逻辑？

二阶提交是一个经典的分布式系统问题，并不是mysql独有的

思考一下，如果redo完整提交了，这时候binlog失败了，由于redo写完以后事务是不能回滚的，如果这还允许回滚，那么会覆盖别的事务的更新，那么如果redo直接提交了，binlog写入失败，回滚不了，造成数据和binlog不一致的

innodb是使用wal技术来提交事务，执行事务的时候，写完内存和日志，事务就算完成了，之后崩溃了，需要依靠日志来恢复数据页

### 可不可以只用redo，不用binlog，来保证数据的持久性

只从崩溃恢复的角度来看只有redo当然是可以，平时使用的数据库默认就没有开启binlog，只要需要主备复制才开启，在实际生产中是必须开启的。如果没开binlog，redo是不存在二阶提交的，但是系统依然是crash-safe

binlog有一些redo不可替代的作用：

归档，redo是循环写的，写到末尾需要回到开头继续写，历史日志无法保留，只使用redo无法完成归档，binlog也是mysql系统高可用的关键，就是binlog复制，还有一些数据分析系统或者数据迁移系统，阿里的数据库增量解析系统canal就是通过订阅mysql的binlog来更新自己的数据，关掉mysql的binlog，这些下游系统就无法使用

### redo log的大小一般设置为多大

redobuffer太小的话，会导致很快就被写满，然后不得不强行刷redobuffer到磁盘，redo满了刷redo这个过程会阻塞系统的所有更新操作，写性能跌到0

### 正常运行的实例，数据最终落盘，是从redobuffer更新过来的还是缓冲池bufferpool更新过来的

redobuffer里面没有记录完整的数据，所以他没有能力去更新磁盘数据页，也就不存在数据最终落盘，是不是由redo更新过去的。

1.如果是正常运行的实例，数据页在bufferpool被改了以后，跟磁盘的数据页不一致了，称为脏页，最终数据落盘，就是把buffer pool中的数据页写入磁盘，这个过程跟redo毫无关系

2.如果是崩溃恢复，innodb会认为一个数据页在崩溃以后发生了丢失更新，会把它读到内存，然后让redo去更新内存，更新完以后buffer pool中的数据页变成了最新的正确的数据，并且变成了脏页，那就需要再从buffer pool刷到磁盘

### 关于mysql的排序orderby

mysql会为每一个线程分配一个内存sortbuffer，用于排序该内存大小的sortbuffersize

如果排序的数量小于sortbuffersize，排序会在内存完成

如果排序的数据量很大，内存中放不下这么多大数据，则会使用磁盘临时文件进行外部排序

外部排序算法是归并排序

mysql会通过索引将满足条件的数据读取到sortbuffer，并且按照排序字段对记录进行排序

如果查询字段不包含在辅助索引中，需要按照辅助索引记录的主键去主键索引树回表查询所需要的字段，这种方式会造成随机IO，mysql对这块的优化是会将普通索引记录的主键取出来在内存排序，然后将排序好的主键去回表搜索

按照情况建立联合索引可以避免排序所带来的性能损耗，允许的情况下也可以建立覆盖索引来避免回表

### 关于部分会影响性能的隐式操作

1.对字段做函数操作，无法使用索引

B+树快速节点定位的能力，来源于同层兄弟节点的有序性

也就是说问题出现在如果对索引字段做函数操作，那么可能会破坏索引值的有序性，因此优化器会放弃走索引树搜索的能力，但是并不是说就不会使用索引了，其实使用explain分析后能看到索引还是被使用的，只不过由于丢失了索引树快速搜索的能力，所在只会在索引树上做全索引扫描

这里需要注意，即使使用的是函数不会破坏索引值的有序性，比如select  * from table where a+1 = 1000;

这个运算并没有破坏有序性，但是优化器偷懒了，直接pass掉，所以需要把这种语句改写成select * from table where a = 1000-1;

2.隐式类型转换

在mysql中，字符串和数字做比较的话，是字符串转换成数字

而这个自动类型转换其实就是在索引字段上使用了函数从而导致优化器放弃使用索引

小实验：如果查询的索引字段是字符串类型，而等号后面填入的整型，那么会发生类型转换，导致使用了函数

但是如果查询的索引字段是整型，而等号后面填入一个字符串，其实是使用索引的

3.如果两个表的字符集不同，在做连接查询的时候用不上关联字段的索引

字符集不同是条件，连接过程中要求在被驱动表的索引字段上加函数操作，这是导致对被驱动表做全表扫描的原因

### 幻读

select * from t where d = 5 for update; 这个语句会找到的d = 5这个行记录，因为在select语句执行完以后，id = 5这一行会加一个当前读写锁，并且会在commit后释放锁

d字段没有加索引，所以这个语句会做全表扫描的，那么被扫描到的，但是不满足条件的记录，会不会加锁？

幻读是指在一个事务内前后两次查询同一个范围，后一次查询看到了前一次查询没看到的行

幻读声明：

1.在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的，因此幻读是在当前读下才会出现

2.幻读仅指的是新插入的行

幻读的影响？

首先是语义上的，select * from t where d = 5 for update的语义是在session开始时要把d = 5的行锁住，不准别的事务进行读写操作，而实际上这个语义被破坏了

其次是数据一致性问题，锁的设计是为了保证数据的一致性，而这个一致性不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性

产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的间隙，因此为了解决幻读问题，innodb只好引入了新的锁，也就是间隙锁

跟间隙锁存在冲突关系的，是往这个间隙中插入一个记录这个操作，间隙锁之间不存在冲突关系

每个间隙锁都有共同的目标：保护这个间隙，不允许插入新值，但他们之间是不冲突的。间隙锁和行锁合称为next key lock，每个next key lock是前开后闭区间，实际上，由于正无穷是开区间，所以innodb存储引擎加了一个不存在的最大值supernum，来满足前开后闭

间隙锁的引入，会导致同样的语句锁住更大的范围，其实影响了并发。间隙锁在RR下才生效，如果不想用间隙锁，可以使用RC，但是需要解决数据和日志不一致的问题，需要把binlog格式设置为ROW

### 加锁规则，包含了两个原则，两个优化和一个bug

原则1：加锁的基本单位是next key lock，是前开后闭区间

原则2：查找过程中访问到的对象才会加锁

优化1：索引上的等值查询，给唯一索引加锁的时候，nkl退化为行锁

优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，nkl会退化为gaplock

bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止

RR遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的

### mysql的性能优化

1.短连接风暴

正常的短连接模式就是连接到数据库后，执行很少的sql语句就断开，下次需要的时候再重连，如果使用的是短连接，业务高峰期时，就可能出现连接数暴涨的问题

mysql建立连接的过程，成本是很高的，除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限

在业务压力比较小的时候，这些额外成本并不明显，但是短连接模型存在一个风险，就是一旦数据库请求处理的慢了，连接数就会暴涨，max_connections参数可以控制一个mysql实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求

对于短连接风暴的解决，可以有两种方式，但都是有损的：

1.先处理掉那占着连接但是不工作的线程

2.减少连接过程的消耗，重启数据库，并使用–skip-grant-tables参数启动，以此来跳过权限验证

### 慢查询性能问题

1.索引没有设计好

2.sql语句没写好

3.mysql选错了索引

导致慢查询的第一种可能是索引没有设计好

这种场景首先应该想到的解决方法是紧急创建索引，mysql5.6以后，已经支持了online DDL，对于那种高峰期已经被这条sqll语句打挂了的情形，最高效的做法就是执行alter table

假如数据库架构是单主单从，主库A，从库B，那么方案流程是这样的：

1.先在备库B上执行set sql_log_bin  = off，意思是停止写入binlog，然后执行alter table语句加上索引

2.执行主备切换

3.这时候主库是B库，然后在从库A上执行第一步操作

实际生产更应该考虑gh-ost这样专门处理mysql online DDL的工具，更加稳妥，但是在紧急需要处理的时候，上面这个方案效率是最高的

导致慢查询的第二种是sql语句没写好

由于有些慢查询问题只能在线上环境复现，所以不可能由于在线上满了就去改代码，然后重新发布上线部署，那么一个解决方案是通过mysql5.7提供的query_rewrite功能，可以把一种查询语句改为另一种查询语句，叫做线上查询重写

导致慢查询的第三种可能是优化器选错了索引

这个时候应急处理是force index，强制使用指定的索引

其实在线上环境更容易出现的情况sql语句问题和索引设置问题，优化器选错索引这个一般会在测试阶段避免

1.上线前，在测试环境，把慢查询日志打开，把最大慢查询时间设置为0，保证每条sql语句都能被录入慢查询日志

2.在测试表里插入模拟线上的数据，做一遍回归测试

3.观察慢查询日志里每类语句的输出，特别留意Rows_examined字段是否与预期一致。

### mysql是怎么保证数据不丢失的

只要redo和binlog保证持久化到磁盘，就能确保mysql异常重启后，数据可以恢复

binlog的写入时机：

事务执行的过程中，先把日志写到binlog cache中，事务提交的时候，再把binlog cache写到binlog文件中

一个事务的binlog是不能拆开的，因此不论这个事务多大，也要确保一次性写入，这就涉及binlog caceh的保存问题，系统为binlog cache分配了一片内存，每个线程都有自己独立的binlog cache，binlog_cache_size可以决定这个内存的大小，如果超过了这个大小，就要暂存到磁盘中，事务提交的时候，执行器会把binlog cache里的完整事务写入到binlog磁盘文件中，并清空binlog_size

可以得到一个结论，每个线程都有一个自己的binlog cache，但是他们对应磁盘中的同一个binlog文件。fsync才是将数据持久化到磁盘的操作，一般情况下我认为fsync才会占用磁盘的IOPS。sync_binlog = N (N > 1)的时候，表示每次提交事务都write，write指的是把日志写入到page_cache,并没有持久化到磁盘，fsync才是持久化到磁盘，sync_binlog = N (N > 1)表示每次提交事务都会write，但是累计N个事务才会fsync，因此，在IO出现瓶颈的时候，将这个N设置为一个比较大的值，可以提升性能，但是如果设置为N，对应的风险是，如果主机发生异常重启，会丢失最近N个事务的binlog日志

redo的写入机制：

事务执行的过程中生成的redo要先写进redobuffer中，但是redobuffer中的内容也不并不是直接持久化到磁盘的

如果事务执行期间mysql发生异常重启，那这部分日志就丢失了，由于事务日志并没有提交，所以这时日志丢了也不会有损失，因为会直接回滚，本来也不需要这部分日志。但是在事务提交前，redobuffer中的部分日志有没有可能被持久化到磁盘，答案是确实会有这种情况

redo的三种存在状态：

1.存在redobuffer中，物理上是在mysql进程内存中

2.写到磁盘，但是没有持久化，物理上是在文件系统的page caceh里

3.持久化到磁盘，对应的是hard disk

innodb有一个后台线程，每隔一秒会把redobuffer中的日志，调用write写到文件系统的page cache中，然后调用fsync持久化到磁盘

注意:事务执行期间redolog也是直接写在redobuffer中，然后redobuffer中的redo也会被后台线程一起持久化到磁盘，也就是说一个还没有提交事务的redo，也有可能已经持久化到磁盘了

除了后台线程每秒一次的刷盘外，还有两种情况会让一个没有提交事务的redo写入到磁盘中

1.redobuffer占用的空间即将达到innodblogbuffersize大小的一半，后台线程会主动写盘，注意由于这个事务并没有提交，所以这个写盘操作只是write，而没有调用fsync，也就是只留在了文件系统的page cache

2.并行事务提交的时候，顺带将这个事务的redobuffer持久化到磁盘中。

通常我们说的mysql双1配置，指的就是sync_binlog和innodb_flush_log_at_trx_commit都设置成 1。也就是说一个事务完整提交前，需要等待两次刷盘，一次是redo的prepare阶段，一次是binlog

两次刷盘意味着假如从mysql看到tps每秒事务处理数是每秒两万的话，那么两次刷盘，相当于每秒要写四万次磁盘，而如果用工具测试磁盘能力，发现磁盘自己都不能应对这么大的iops，那么mysql是怎么做到这个两万的tps的？

这就是组提交机制 （group commit）

概念：日志逻辑序列号（LSN）lsn是递增的，用来对应redo 的一个个写入点，每次写入长度为length的redolog，lsn的值就会加上length

三个并发事务在redobuffe的prepare阶段，都已经写完，准备持久化，对应着三个不同的LSN，当有第一个事务到达时，会被选为这组的leader，然后leader开始写盘，这个组里有三个事务，LSN变为这个组里最大的一个LSN，他去写盘的时候会带上这个lsn，因此当leader返回的时候所有lsn小于这个值的事务都已经持久化完毕，所以这时候剩下两个事务可以直接返回，所以一个组里，成员越多，节约磁盘iops的效果越好，但是如果是单线程，那就一个事务对应一次持久化操作

为了让一次fsync带的组员更多，mysql有一个很有趣的优化：拖时间

写入redo，处于prepare阶段-》写binlog-》提交事务，处于commit状态，其实这里面binlog的写入是分为两步操作的，先把binlog从binlog cache写到磁盘的binlog page cache，然后调用fsync持久化

wal机制是减少磁盘写，可是每次事务提交都会写redo和binlog，这磁盘写次数真的变少了吗？

wal机制主要得益于两个方面：

1.redo和binlog都是顺序写的，磁盘的顺序写比随机写速度快

2.组提交机制，可以大幅降低磁盘的iops消耗

### 综上，如果mysql出现性能瓶颈，而且瓶颈是io，那么优化方案如下：

1.设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数，这个方式就是基于额外的故意等待，因此可能会增加语句的响应时间，但是没有丢数据的风险

2.将sync_binlog的值设置为（100-1000），风险是宕机会丢binlog日志

3.将innodb_flush_log_at_trx_commit设置为2，风险是，主动宕机可能会丢数据

### binlog的格式

binlog_format=statement时，日志中记录的是sql语句的原文，并且在sql语句之前还有一个use 库名的操作，我猜测它的目的是binlog的主要作用是归档和主备复制，那么在主备复制的时候，不管是什么线程都应该能正确的找到那个库的那张表

除此以外呢，如果开启事务的话前面还会有begin，结尾会有commit，并且commit后面会跟一个xid等于xxx的信息，说到commit，想到mysql在宕机恢复的时候，如果有这样一种场景，首先由于二阶提交，redo会被先写到prepare状态，然后写binlog，然后在redo commit状态，如果这时候redo 已经是prepare状态，正在写binlog，宕机了，那么重启后它的恢复逻辑是判断binlog完不完整，而这个判断完整的依据就是binlog的这个commit字段，一个完整的事务写的binlog在结尾一定有commit字段

binlog_format=row时，前后的begin和commit是一样的，但是row格式的binlog里没有了sql语句原文，转而用event，也就是事件来代替，

首先有一个table_map_event,用来说明接下来操作的表是哪个库的哪个表

然后是相应的更新逻辑。比如删除就是delete_row_event,其实真正更多的详细信息需要通过mysqlbinlog工具来查看。

为什么会有mixed这种方案：

因为有些statement格式的binlog可能会导致主备不一致，所以这种特殊情况就需要使用row

而使用row的话缺点是很占用空间，比如一个delete语句删除十万行数据，用statement就是表示就是一个sql语句的事情，但是row的话会把十万条记录都写到binlog中，造成很大的空间占用，那么写binlog就会很耗费io资源，影响执行的速度。

所以mysql就取了个折中的方案，mixed，mysql会自己判断这条sql语句是否可能引起主备不一致的情况，如果有可能，就用row，否则用statement

当然现在线上场景更多的使用row，主要好处是数据恢复

即使执行的是delete语句，row格式的binlog也会把被删除掉的行的整行信息保存起来，所以如果在执行完一条语句后发现删错了，直接把delete改为insert这行数据就ok了，如果是insert，会记录所有的字段信息，这些信息可以精准定位刚刚被插入的那一行，然后insert转delete，如果是update，binlog会记录修改前整行的记录和修改后整行的记录，所以如果错误执行了update，只需要把这两个event对调一下再去执行就ok了