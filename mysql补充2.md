### 由delete drop引出重建表相关

innodb_file_per_table设置为ON，是推荐做法，表示将每个innodb表数据存储在一个以.ibd结尾的文件中

而且当不需要这个表的时候，通过drop table命令，可以直接删除这个文件，而如果是放在共享表空间中，即使表删除了，空间也是不会回收的

在删除整个表的时候，可以使用drop table命令回收表空间，但是实际遇到的更多的场景是删除其中的记录，这就衍生出一个问题，为什么表中的数据删除了，但是表空间没有被回收

如果使用delete命令删除表中所有的数据，结果是所有的数据页都被标记为可复用，但是磁盘上，文件不会变小，也就是说通过delete不能回收表空间，只是把数据页标记为了可复用，这就感觉像是表中有了一些空洞一样

不只是删除数据会造成空洞，插入数据也会

如果数据是按索引递增顺序插入，那么索引是紧凑的，但是如果是随机插入，那么可能造成索引的页分裂

也就是说经过大量增删改的表，都是可能存在空洞的，如果能把这些空洞去掉，就能达到收缩表空间的目的

重建表就能达到这个目的

重建表的思路是建立一张与表A结构相同的表B，然后将表A的数据按主键索引递增的顺序插入到表B，很显然，表B的主键索引更紧凑，数据页的利用率也更高，如果把表B作为临时表，插入完成以后，用表B替换表A ，就完成了表的重建工作。

但是上面这种做法一个问题，如果在从表A往临时表B中插入数据的时候，表A又有了新的数据，那么重建完成以后还造成更新丢失的情况，所以在插入临时表期间，不可以更新。这是mysql5.6以前的版本，没有online DDL功能

可以通过alter table A engine = innodb

在mysql5.6以后，引入了online DDL，步骤是：

1.建立一个临时文件，扫描表A主键的所在数据页

2.用数据页中表A的记录生成一个B+树，放到临时文件中

3.生成临时文件时，也就是往临时表添加数据的过程中，会把表A的更新操作记录起来，记录到一个叫rowlog 的文件中

4.临时文件生成以后，将日志文件中的操作应用的临时文件，得到一个逻辑上与表A一致的临时表B

5.将表B替换表A，完成重建工作

在线DDL需要在DDL之前拿到MDL写锁，虽然MDL写锁最终会降级成MDL读锁，是可以在DDL期间进行更新操作的，不阻塞更新操作，至于说不直接解锁的原因是为了保护自己，防止其它线程也对这个表做DDL操作，MDL是一个表级锁

对于一个大表来说，重建表最耗时的操作是拷贝数据到临时表的时间，但是这个过程可以接收增删改操作，所以对于整个DDL过程来说，锁的时间只是刚开始获取MDL写锁，然后降级为MDL读锁，做DDL的过程中相当于一直是表级锁MDL的读锁状态，不阻塞，所以业务上看起来就是online DDL，但是即使不阻塞，对于很大的表，这个操作还是很消耗IO和CPU的

inplace概念：

根据表A重建出来的数据是放在temp_file中的，这个临时文件时innodb在内部创建出来的，整个DDL过程都是在innodb内部完成的，对于server层来说，没有把数据挪到临时表，是一个原地操作，这就是inplace名称的来源

mysql5.6开始，alter table t engine = innodb默认就是recreate过程

analyze table ：对表的索引信息做重新统计，没有修改数据，这个过程会加MDL读锁

optimize table等于recreate + analyze

### 关于count(*)

对于不同的存储引擎，count(*)的实现是不同的。

myisam会把一个表的总行数存放在磁盘上，因此执行count(*)的时候直接返回这个数，效率很高

innodb比较麻烦，在执行count(*)的时候，需要把数据一行一行从引擎中取出来，然后累积计数

innodb没有把这个总行数像myisam一样把行数存起来是因为即使是在同一时刻的多个查询，由于多版本并发控制，innodb对于应该返回多少行也是不确定的。

思考这样一个场景：同一时刻有三个会话：

![image](https://cdn.jsdelivr.net/gh/chen-xing/figure_bed_02/cdn/20210903140209854.png)

由于多版本并发控制，不同会话只能读取到当前会话事务开启那一刻的数据快照，并且在同一个事务内，多次读取都是以那个快照版本为准，如果是RR的话，这是可重复读实现的根本依据

那么可以看到对于第一个会话，它开启的时候数据总共有10000行，所以不管这个事务运行了多长时间，最终返回都是10000，会话B比会话A开启的晚，晚到会话C已经插入了一行才开启，这时候读到了这个快照版本，所以在他的事务内，它自己也插入了一条记录，最终读到的就是10002，对于会话C，它在自己的事务内插入一条记录，最终读取的也是自己快照版本+1，最终三个会话在同一时刻在各自的事务内读出来了三个不同的结果

这种情况是跟innodb实现事务有关，RR是默认隔离级别，在代码上通过mvcc多版本并发控制来实现，每一行记录都判断自己是否对这个会话可见，因此count(*)只好把数据一行一行读取出来，可见的行才能用于统计计算

所以由于事务的原因，innodb是无法像myisam一样直接存统计结果，mysql对count(*)是有一定优化的：innodb是索引组织表，主键索引树的叶子节点是整行数据，普通索引树的叶子节点是主键值，所以普通索引树的大小是远小于主键索引树的，但是对这两棵树做数字统计运算的逻辑结果是一致的，因此，mysql会找较小的那颗树进行遍历

count(*)和count（主键id）count（1）都是表示返回满足条件的结果集的总行数，而count（字段），表示返回满足条件的数据行里面，参数字段不为null的总个数

对于count（主键id）来说，innodb会遍历整张表，每一行的id值都取出来，返回给server层，server层拿到id后，判断是不可能为空的，就按行累加，其实对于count(主键id)这个是可以优化成与count(*)一样逻辑的，但是并没有，所以建议直接count(※)

对于count（1）来说，innodb会遍历整张表，但不取值，server层对于返回的每一行，放一个数字1进去，判断是不可能为空的，按行累加

count（1）是比count（主键id）要快，因为引擎层需要返回id涉及到解析数据行，以及拷贝字段值的操作

对于count（字段）来说：由于要判断行记录中的字段，所以肯定需要走主键索引拿到行记录，在行记录中拿到字段，进行null判断

1.如果这个字段是定义为not null，那么就取出所有行中的这个字段，判断不能为null，按行累加

2.如果字段定义允许为null，那么执行的时候判断是否为null，不是null才累加

count(*)做了优化，也就是在索引树较小的树上遍历，并不会直接在主键索引树上遍历，并且取出结果以后不取值，而且肯定不是null，直接累加，按照效率：count（字段）< count（主键id）< count（1）<  count（※）

### 关于二阶段提交不在不同时刻出现异常的情况

1.当在写入redo然后处于redo的prepare状态的时候，在写binlog，这个期间发生了宕机，由于此时binlog还没写，redo也没commit，所以在崩溃恢复的时候事务会回滚，这个时候binlog没写，错误信息不会转移到从库

2.如果在redo prepare后，并且binlog也开始写了，在写binlog到redo的commit标识这段时间内，如果宕机，这个时候崩溃恢复需要有一个判断规则：

如果redo里面的事务是完整的，也就是里面已经有了commit标识，则宕机后直接恢复

如果redo里面的事务只有完成的prepare，则判断对应的事务的binlog是否完整，如果binlog是完整的，则提交事务，否则回滚事务

所以如果在redo的一阶提交完成以后，也就是prepare后，并且binlog已经写完了，这时候的崩溃恢复是会提交事务的

### 如何判断崩溃恢复时binlog是否完整？

一个完整的binlog是有完整格式的：

对于statement格式的binlog，最后会有commit

对于row格式的binlog，最后会有一个XIDevent

对于5.6以后，还引入了binlog-checksum参数，用来验证binlog内容的正确性，对于binlog日志由于磁盘原因，可能会在日志中间出错的情况，mysql可以通过checksum的结果来发现

### redolog和binlog的联系

他们有一个共同的字段是xid，崩溃恢复的时候会按顺序扫描redo

如果在redo中找到了prepare标识和commit，那么可以证明binlog已经写入完整，直接提交

如果redo中只有prepare，没有commit，就拿着xid去binlog找对应的事务

### 处于prepare阶段的redo加上完整的binlog，重启就能恢复

因为一旦有了完整的binlog，那么从库就可以拿去使用做主从复制了，所以主库一定要提交事务，从而保证主库和从库之间的数据一致性

### 那么接上一个问题，为什么还需要二阶提交，直接干脆先把redo完整写完，再写binlog，必须两个日志完整，才可以提交，不是一样的逻辑？

二阶提交是一个经典的分布式系统问题，并不是mysql独有的

思考一下，如果redo完整提交了，这时候binlog失败了，由于redo写完以后事务是不能回滚的，如果这还允许回滚，那么会覆盖别的事务的更新，那么如果redo直接提交了，binlog写入失败，回滚不了，造成数据和binlog不一致的

innodb是使用wal技术来提交事务，执行事务的时候，写完内存和日志，事务就算完成了，之后崩溃了，需要依靠日志来恢复数据页

### 可不可以只用redo，不用binlog，来保证数据的持久性

只从崩溃恢复的角度来看只有redo当然是可以，平时使用的数据库默认就没有开启binlog，只要需要主备复制才开启，在实际生产中是必须开启的。如果没开binlog，redo是不存在二阶提交的，但是系统依然是crash-safe

binlog有一些redo不可替代的作用：

归档，redo是循环写的，写到末尾需要回到开头继续写，历史日志无法保留，只使用redo无法完成归档，binlog也是mysql系统高可用的关键，就是binlog复制，还有一些数据分析系统或者数据迁移系统，阿里的数据库增量解析系统canal就是通过订阅mysql的binlog来更新自己的数据，关掉mysql的binlog，这些下游系统就无法使用

### redo log的大小一般设置为多大

redobuffer太小的话，会导致很快就被写满，然后不得不强行刷redobuffer到磁盘，redo满了刷redo这个过程会阻塞系统的所有更新操作，写性能跌到0

### 正常运行的实例，数据最终落盘，是从redobuffer更新过来的还是缓冲池bufferpool更新过来的

redobuffer里面没有记录完整的数据，所以他没有能力去更新磁盘数据页，也就不存在数据最终落盘，是不是由redo更新过去的。

1.如果是正常运行的实例，数据页在bufferpool被改了以后，跟磁盘的数据页不一致了，称为脏页，最终数据落盘，就是把buffer pool中的数据页写入磁盘，这个过程跟redo毫无关系

2.如果是崩溃恢复，innodb会认为一个数据页在崩溃以后发生了丢失更新，会把它读到内存，然后让redo去更新内存，更新完以后buffer pool中的数据页变成了最新的正确的数据，并且变成了脏页，那就需要再从buffer pool刷到磁盘

### 关于mysql的排序orderby

mysql会为每一个线程分配一个内存sortbuffer，用于排序该内存大小的sortbuffersize

如果排序的数量小于sortbuffersize，排序会在内存完成

如果排序的数据量很大，内存中放不下这么多大数据，则会使用磁盘临时文件进行外部排序

外部排序算法是归并排序

mysql会通过索引将满足条件的数据读取到sortbuffer，并且按照排序字段对记录进行排序

如果查询字段不包含在辅助索引中，需要按照辅助索引记录的主键去主键索引树回表查询所需要的字段，这种方式会造成随机IO，mysql对这块的优化是会将普通索引记录的主键取出来在内存排序，然后将排序好的主键去回表搜索

按照情况建立联合索引可以避免排序所带来的性能损耗，允许的情况下也可以建立覆盖索引来避免回表

### 关于部分会影响性能的隐式操作

1.对字段做函数操作，无法使用索引

B+树快速节点定位的能力，来源于同层兄弟节点的有序性

也就是说问题出现在如果对索引字段做函数操作，那么可能会破坏索引值的有序性，因此优化器会放弃走索引树搜索的能力，但是并不是说就不会使用索引了，其实使用explain分析后能看到索引还是被使用的，只不过由于丢失了索引树快速搜索的能力，所在只会在索引树上做全索引扫描

这里需要注意，即使使用的是函数不会破坏索引值的有序性，比如select  * from table where a+1 = 1000;

这个运算并没有破坏有序性，但是优化器偷懒了，直接pass掉，所以需要把这种语句改写成select * from table where a = 1000-1;

2.隐式类型转换

在mysql中，字符串和数字做比较的话，是字符串转换成数字

而这个自动类型转换其实就是在索引字段上使用了函数从而导致优化器放弃使用索引

小实验：如果查询的索引字段是字符串类型，而等号后面填入的整型，那么会发生类型转换，导致使用了函数

但是如果查询的索引字段是整型，而等号后面填入一个字符串，其实是使用索引的

3.如果两个表的字符集不同，在做连接查询的时候用不上关联字段的索引

字符集不同是条件，连接过程中要求在被驱动表的索引字段上加函数操作，这是导致对被驱动表做全表扫描的原因