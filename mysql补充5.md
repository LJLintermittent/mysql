使用前缀索引前最好使用select count(distinct left(idnex,3/4/5/6/7....)) / count(*) as 1,2,,3,4,5,6,7...

使用这样的sql语句，即使用基数（索引列中不重复的索引值的个数）除以 总记录数来得到这个前缀索引的区分度

区分度越高查找效率越高，能过滤掉更多的行，另外需要注意的是前缀索引无法使用orderby和groupby，当然由于前缀索引不完整，也无法使用覆盖索引来避免回表

如果没有定义主键，innodb会选择一个唯一的非空索引作为替代，如果没有这样的索引， innodb会隐式的定义一个主键来作为聚集索引。

对于聚集索引来说，插入速度严重依赖插入顺序，如果是按照主键递增的顺序来插入，那么是最快的方式，如果不是的话，最好在插入完成以后使用optimize table命令重新组织表

对于聚集索引，每一个叶子节点都包含了主键值，事务id，用于事务和MVCC的回滚指针，以及剩余列

innodb在插入之前不得不先找到并且从磁盘中读取目标页到内存中。如果写入是乱序的，innodb不得不频繁地做页分裂操作，以便为新的行分配空间。所以在使用聚集索引时，尽量使用按照主键的顺序插入数据，并且尽可能的使用单调增加的聚集键的值来插入数据

#### 慢查询优化：

1.优化数据访问：是否向数据库请求了不需要的数据

有些查询会请求超过实际需要的数据， 然后这些多余的数据会被应用程序丢弃，这会给mysql服务器带来额外的负担，并增加网络开销，另外也会消耗服务器的CPU和内存资源

2.响应时间，扫描的行数，返回的行数

在explain语句中的type列反应了访问的类型，访问类型有很多种，从全表扫描到索引扫描，范围扫描，唯一索引扫描，常数引用等，速度从慢到快，扫描的行数也是从多到少

一般mysql使用三种方式来应用where条件：

1.在索引中使用where条件来过滤不匹配的记录，这是在存储引擎层中完成的 

2.使用覆盖索引扫描，extra列出现using index来返回记录，直接从索引中过滤不需要的记录并返回命中的结果，这是在mysql服务器层完成的，但无须再回表查询记录

3.从数据表中返回数据，然后过滤不满足条件的记录，extra中出现using where，这是在mysql服务器层完成的，mysql需要先从数据表中读出记录然后过滤

#### limit查询优化

当系统中需要进行分页操作的时候，通常会使用limit加上偏移量的方式，limit后面可以跟一个参数或者两个参数，如果是跟一个参数，那么代表的是返回多少行，如果是两个参数，那么第一个参数是行偏移量的意思，即要返回的第一行数据从多少行开始计算

那么使用limit最大的问题就是当行偏移量这个参数过大的时候，需要扫描很多的行，最终只返回需要的行，不需要的行都需要被抛弃，代价非常高，这种方式平均需要访问半个表的数据

对于limit的优化思路：

在主查询中写一个子查询，这个子查询只需要查询尽可能少的数据，子查询要带limit条件，一般就是在这个带limit的子查询中只查询出来主键id，然后把这个子查询作为一张临时表temp，在主查询中带上where条件，temp.id = user.id，这样外面的表不论查询哪些字段都是直接使用主键id进行查询，速度会非常快。优化limit的最简单的方式就是使用覆盖索引，而不是查询所有的列

select * from user uc ,(select id from user orderby create_time limit 10000,10) as temp where temp.id  = uc.id;(延迟关联的思想)

select id from user orderby create_time limit 10000,10这一句快的核心原因就在于我查的主键id，这里面会使用create_time的普通索引，那么普通索引的叶子节点不就是主键id，所以这条sql语句一定不需要回表，extra列一定会显示using index，核心的limit操作优化成了不需要回表以后，分页的效果也出来了，因为拿到了分页效果的主键id。那么对于外层查询，主键id直接走主键索引树，也很快就能查到完整的行记录

#### union查询优化

mysql总是通过创建临时表的方式来执行union查询，除非是必须需要服务器来消除重复的行（单独使用union查询服务器会在临时表中加一个distinct来去重），否则都使用union all（union all 不会去除重复的行），在临时表中进行去重会对整个临时表的数据做一个唯一性检查，这个代价通常很大。

**innodb_flush_log_at_trx_commit = 0**

innodb中的io thread每隔一秒将log buffer中的数据写入到操作系统缓存，然后通知操作系统进行fsync，保证数据被写入到物理文件中真正持久化，由于每隔一秒触发一次这样的操作，所以并不是每次事务提交都会触发，那么在极端情况下，mysql crash或者os crash 或者主机断电都会导致丢失一秒的数据

**innodb_flush_log_at_trx_commit = 1**

innodb中的 io thread在每次事务提交的时候都会将log buffer中的数据写入到操作系统的文件系统的缓存中，并且立即调用fsync，将数据做持久化处理，这个是最安全的情况，最极端情况是会丢失这一次事务的数据，那么也就是说已经提交过的事务都不会丢失

**innodb_flush_log_at_trx_commit = 2**

这个是每次事务提交的时候都会将数据写入到操作系统的文件系统的缓存中，但是这个还是相当于在内存中，而真正的fsync操作对于innodb来说并不知道什么时候执行，所以这种情况下发生mysql crash不会导致丢失数据，但是如果os crash 或者主机断电那么就会丢失没有保存的数据，使用这种方案可以大大提高效率，但是注意通过蓄电池后备的主机方式来保证主机不会断电，并且通过异地容灾来保证主机是正常的

对于1这种方式来说，会导致写入操作的性能大幅下降，但是1这种配置还是系统的默认位置

需要注意的是对于innodb_flush_log_at_trx_commit这个参数，针对是redolog的内容，当在mysql中对innodb表进行更改的时候，这些更改首先存储在innodb日志缓冲区的内存中，也就是log buffer中，然后在写到磁盘中的redolog文件中，当然中途还需要先放到操作系统缓存中，然后再fsync刷盘。

##### 再次注意上面的参数说的log buffer全称应该是redo log buffer

而sync_binlog这个参数针对的是binlog日志内容的刷盘策略

sync_binlog = 0为默认配置，表示mysql不控制binlog的刷新，当事务提交以后，mysql不管什么时候进行fsync，完全交给操作系统，这时候性能最好，风险最大，单纯的mysql crash 无所谓，如果主机crash，那么会损失很多的binlog日志内容。

sync_binlog = N，如果设置为1，那么每次事务提交前都会强制刷盘，最安全性能最低，即使主机 crash ，也最多损失一个事务的binlog数据

一般会设置N = 500或者1000，表示没进行N次事务提交，才进行一次fsync。

另外如果设置为1，那么即使系统crash，丢失的也是一个没有完成的事务，对实际数据并没有造成任何影响

sync_binlog = 1是推荐配置，mysql会在每次提交事务前将二进制日志同步到磁盘（fsync），保证在服务器崩溃的时候不会出现binlog丢失的问题，因为如果在刷盘的时候宕机了，那么事务也走不到提交，最终会回滚数据，所以数据是绝对安全的，另外由于二阶提交，即使binlog写完，刷盘完，其实还要将redo的状态变为commit才算正式提交，这个redocommit 状态会去检查binlog是否完整，如果不完整证明前面写binlog的时候宕机了，那么就不提交事务，会回滚的

### 复制

mysql的复制主要有三步：

1.在主库上把数据的更改记录到二进制日志中

2.备库将主库上的日志复制到自己的中继日志中（relay log），使用io线程

3.备库使用sql线程将relay log中的内容读取并重放，从而达到主从复制的效果

第一步是将主库上记录二进制文件，在每次准备提交事务完成数据更新，主库将数据更新的事件记录到二进制日志文件中（重点是提交事务之前，binlog就要写完），mysql会按照事务提交的顺序而非每条语句执行的顺序来记录二进制日志，在记录好了二进制数据后，会告诉存储引擎可以提交事务了

第二步备库将主库中的二进制文件通过io 线程将其复制到本地的中继日志中

备库的sql线程执行最后一步，该线程从中继日志中读取事件并在备库中执行，从而实现备库数据的更新，当sql线程追上io线程时，中继日志通常已经在系统缓存中了，所以中继日志的开销很低。

这种复制的架构实现了获取事件和重放事件的解耦，允许这两个线程异步执行，也就是说io线程和sql线程互不干扰。

复制的技术步骤：

1.在每台服务器上创建复制账号

2.配置主库和从库

3.通知备库连接到主库并从主库中复制数据